<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | Metehan Cekic</title>
    <link>https://www.ece.ucsb.edu/~metehancekic/categories/deep-learning/</link>
      <atom:link href="https://www.ece.ucsb.edu/~metehancekic/categories/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 03 May 2020 13:36:47 -0700</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=true) shape:circle]</url>
      <title>Deep Learning</title>
      <link>https://www.ece.ucsb.edu/~metehancekic/categories/deep-learning/</link>
    </image>
    
    <item>
      <title>Deep Illusion (Adversarial ML toolbox)</title>
      <link>https://www.ece.ucsb.edu/~metehancekic/project/deep-illusion/</link>
      <pubDate>Sun, 03 May 2020 13:36:47 -0700</pubDate>
      <guid>https://www.ece.ucsb.edu/~metehancekic/project/deep-illusion/</guid>
      <description>&lt;br/&gt;
&lt;h2 id=&#34;deep-illusion-&#34;&gt;Deep Illusion&lt;/h2&gt;
&lt;p&gt;Deep Illusion is a toolbox for adversarial attacks in machine learning. Current version is only implemented for Pytorch models. DeepIllusion is a growing and developing python module which aims to help adversarial machine learning community to accelerate their research. Module currently includes complete implementation of well-known attacks (PGD, FGSM, R-FGSM, CW, BIM etc..). All attacks have an apex(amp) version which you can run your attacks fast and accurately. We strongly recommend that amp versions should only be used for adversarial training since it may have gradient masking issues after neural net gets confident about its decisions. All attack methods have an option (Verbose: False) to check if gradient masking is happening.&lt;/p&gt;
&lt;p&gt;All attack codes are written in functional programming style, therefore, users can easily call the method function and feed the input data and model to get perturbations. All codes are documented, and contains the example use in their description. Users can easily access the documentation by typing &amp;ldquo;??&amp;rdquo; at the and of the method they want to use in Ipython (E.g FGSM?? or PGD??). Output perturbations are already clipped for each image to prevent illegal pixel values. We are open to contributers to expand the attack methods arsenal.&lt;/p&gt;
&lt;p&gt;We also include the most effective current approach to defend DNNs against adversarial perturbations which is training the network using adversarially perturbed examples. Adversarial training and testing methods are included in torchdefenses submodule.&lt;/p&gt;
&lt;p&gt;To standardize the arguments for all attacks, methods accept attack parameters as a dictionary named as attack_params which contains the necessary parameters for each attack. Furthermore, attack methods get the data properties such as the maximum and the minimum pixel value as another dictionary named data_params. These dictinaries make function calls concise and standard for all methods.&lt;/p&gt;
&lt;p&gt;Current version is tested with different defense methods and the standard models for verification and we observed the reported accuracies.&lt;/p&gt;
&lt;p&gt;Code can be installed via PyPi:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install deepillusion
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
&lt;a href=&#34;https://pypi.org/project/deepillusion/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyPi page for the code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/metehancekic/deep-illusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Git repo for the code&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sparsifying Front Ends</title>
      <link>https://www.ece.ucsb.edu/~metehancekic/project/adversarial-machine-learning/</link>
      <pubDate>Thu, 05 Mar 2020 15:01:28 -0800</pubDate>
      <guid>https://www.ece.ucsb.edu/~metehancekic/project/adversarial-machine-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Radio Frequency Machine Learning (RFML)</title>
      <link>https://www.ece.ucsb.edu/~metehancekic/project/mywireless-fingerprinting/</link>
      <pubDate>Tue, 25 Feb 2020 14:49:34 -0800</pubDate>
      <guid>https://www.ece.ucsb.edu/~metehancekic/project/mywireless-fingerprinting/</guid>
      <description>&lt;h2 id=&#34;radio-frequency-machine-learning-&#34;&gt;&lt;strong&gt;Radio Frequency Machine Learning&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
	&lt;li&gt;Our goal is to learn&amp;nbsp;&lt;strong&gt;&lt;em&gt;RF signatures&lt;/em&gt;&lt;/strong&gt;&amp;nbsp;that can distinguish between devices sending&amp;nbsp;&lt;em&gt;exactly&lt;/em&gt;&amp;nbsp;the same message. This is possible due to subtle hardware imperfections (labeled&amp;nbsp;&#34;nonlinearities&#34; in the figure below) unique to each device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;Simply Easy Learning&#34; width=&#34;600&#34;
height=&#34;240&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Since the information in RF data resides in complex baseband, we employ CNNs with complex-valued weights to learn these signatures. This technique&amp;nbsp;does&amp;nbsp;not use&amp;nbsp;signal domain knowledge and can be used for any wireless protocol. We demonstrate its effectiveness for two protocols -&amp;nbsp;WiFi and ADS-B.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;architect.png&#34; alt=&#34;Simply Easy Learning&#34; width=&#34;600&#34;
height=&#34;240&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;We show that this&amp;nbsp;approach is vulnerable to spoofing&amp;nbsp;when using&amp;nbsp;the entire packet:&amp;nbsp;the CNN focuses on&amp;nbsp;fields containing ID info (eg. MAC ID in WiFi) which can be easily spoofed. When using the preamble alone, reasonably high accuracies are obtained, and performance is significantly enhanced by noise augmentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;We also study robustness to confounding factors&amp;nbsp;in data collected over multiple days and locations, such as the carrier frequency offset (CFO), which drifts over time, and the wireless channel, which depends on the propagation environment. We show that carefully designed data augmentation is critical for learning robust wireless signatures.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;small&gt;&amp;nbsp;&lt;/small&gt;&lt;/p&gt;
&lt;div class=&#34;field__item odd&#34;&gt;&lt;div class=&#34;entity entity-paragraphs-item paragraphs-item-related-publications-topic-group&#34;&gt;
  &lt;div class=&#34;content&#34;&gt;
    &lt;div class=&#34;field field--name-field-sub-topic-title field--type-text field--label-hidden&#34;&gt;&lt;div class=&#34;field__items&#34;&gt;&lt;div class=&#34;field__item even&#34;&gt;&lt;h3 class=&#34;&#34;&gt;Publications&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&#34;field field--name-field-related-publications field--type-entityreference field--label-hidden&#34;&gt;&lt;div class=&#34;field__items&#34;&gt;&lt;div class=&#34;field__item even&#34;&gt;	&lt;div role=&#34;article&#34; class=&#34;node node--simple-publication node--promoted contextual-links-region node--citation node--simple-publication--citation&#34;&gt;
	  &lt;div class=&#34;node__content&#34;&gt;
	    &lt;div class=&#34;field citation&#34;&gt; &lt;b&gt;Metehan Cekic*&lt;/b&gt;,&amp;nbsp;Soorya Gopalakrishnan*,&amp;nbsp;Upamanyu Madhow, &#34;&lt;a href=&#34;https://web.ece.ucsb.edu/~metehancekic/publication/cekic-2020-robust/&#34; target=&#34;_self&#34;&gt;Robust Wireless Fingerprinting: Generalizing Across Space and Time&lt;/a&gt;&#34;, arXiv:2002.10791.
&lt;br/&gt;
&lt;br/&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;field field--name-field-related-publications field--type-entityreference field--label-hidden&#34;&gt;&lt;div class=&#34;field__items&#34;&gt;&lt;div class=&#34;field__item even&#34;&gt;	&lt;div role=&#34;article&#34; class=&#34;node node--simple-publication node--promoted contextual-links-region node--citation node--simple-publication--citation&#34;&gt;
	  &lt;div class=&#34;node__content&#34;&gt;
	    &lt;div class=&#34;field citation&#34;&gt;Soorya Gopalakrishnan*, &lt;b&gt; Metehan Cekic* &lt;/b&gt;,&amp;nbsp;Upamanyu Madhow, &#34;&lt;a href=&#34;https://www.ece.ucsb.edu/~metehancekic/publication/fingerprinting-2019-globecom/&#34; target=&#34;_self&#34;&gt;Robust Wireless Fingerprinting via Complex-Valued Neural Networks&lt;/a&gt;&#34;, &lt;i&gt;IEEE Global Communications Conference (Globecom)&lt;/i&gt;,&amp;nbsp;Waikoloa, Hawaii, Dec. 2019. 
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
